# Cohere-LangChain-RAG
Retrieval Augmented Generation (RAG) is a process in which the model retrieves contextual documents from an external data source. In this notebook we will demonstrate how to use Cohere Generate model to answer questions using a library of documents as a reference, by using Cohere embedding model for document embeddings and retrieval.

The Cohere Platform empowers enterprises and developers to use Large Language Models (LLMs) privately and securely with AWS JumpStart deployment. We have announced the availability of Cohere’s LLMs through Amazon SageMaker in Jan 2023. Customers can easily subscribe Cohere’s LLMs through AWS Marketplace and use them in Amazon SageMaker.

Command is Cohere’s text generation model. It is trained to follow user commands and to be instantly useful in practical business applications. Command ranks at the top of the Holistic Evaluation of Language Models (HELM) benchmark, an evaluation leaderboard comparing large language models on a wide number of tasks. Cohere Multilingual Embedding Model allows you to classify, embed, and tokenize text in multiple languages.

In this notebook, we will use Cohere Generate Model - Command-Light for text generation and Cohere Multilingual Embedding Model for text embedding. You can follow the Cohere model deployment jupyterbooks in this github for each model deployment.

